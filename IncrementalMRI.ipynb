{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2905faad-6641-424f-8e0d-cdd9ff83d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import layers\n",
    "import models\n",
    "import utility as uty\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d9dc2-9485-4e2c-9c8d-bb092a84c34f",
   "metadata": {},
   "source": [
    "## GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3aac06-e539-4bb2-9bd6-5c77ca58d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Logical GPUs: 1\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "tf version:  2.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 12:06:15.791675: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-01 12:06:16.227927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79111 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:41:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "GPUs = '2'\n",
    "\n",
    "uty.handle_GPUs(GPUs=GPUs, enable_GPU=1,)\n",
    "\n",
    "tf_mirror_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print('tf version: ', tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddf56de-5233-450a-bbe3-2ded430c2845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model_with_layer_search(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, inputs, outputs, **kwargs):\n",
    "        \n",
    "        super(Model_with_layer_search, self).__init__(inputs, outputs, **kwargs)\n",
    "        self.w_init = self.get_weights()\n",
    "        pass\n",
    "    \n",
    "    # extract one layer\n",
    "    def get_layer_by_name(self, name):\n",
    "        \n",
    "        \"\"\"\n",
    "        returns the layer with specified name.\n",
    "        \n",
    "        name: name of the layer to return\n",
    "        \"\"\"\n",
    "        \n",
    "        return self._get_layer_by_name(name)\n",
    "    \n",
    "    def _get_layer_by_name(self, name, model=None, _found_layer=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        return the layer with the desired exact name.\n",
    "        !!! Always give \"_found_layer=None\".\n",
    "        !!! Give \"model=None\" to search the current model. \n",
    "        \"\"\"\n",
    "        \n",
    "        if _found_layer is not None:\n",
    "            return _found_layer\n",
    "        \n",
    "        else:\n",
    "            if model is None:\n",
    "                model = self\n",
    "\n",
    "            for l in model.layers:\n",
    "                if not('.Functional' in str(l)):\n",
    "                    if l.name==name:\n",
    "                        return l\n",
    "                else:\n",
    "                    _found_layer = self._get_layer_by_name(name, l, _found_layer)\n",
    "                    if _found_layer:\n",
    "                        break\n",
    "        return _found_layer\n",
    "    \n",
    "    def re_initialize(self, seed=None, Initializer=tf.keras.initializers.GlorotUniform):\n",
    "        \n",
    "        \"\"\"\n",
    "        The model is re-initialized with the initial random weights.\n",
    "        If seed is not None or is 0, the weights are randomly drawn with that seed from Gloriotd init.\n",
    "        \"\"\"\n",
    "        \n",
    "        w_new = self.w_init\n",
    "        if seed is not None and seed!=0:\n",
    "            ini = Initializer(seed=seed)\n",
    "            for i, w_tmp in enumerate(w_new):\n",
    "                w_new[i] = ini(np.shape(w_tmp), dtype=tf.float32)\n",
    "        \n",
    "        self.set_weights(w_new)\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotate_corners(im):\n",
    "        \"\"\"\n",
    "        Splits the image in 4 windows and rotates them by 180Â°.\n",
    "\n",
    "        This enambles to visualize the mask coherentely\n",
    "        with our paper and with the original paper or LOUPE.\n",
    "        \"\"\"\n",
    "\n",
    "        def rot180(inp):\n",
    "            return np.rot90(np.rot90(inp))\n",
    "\n",
    "        row = np.shape(im)[0]//2\n",
    "        col = np.shape(im)[1]//2\n",
    "\n",
    "        im[:row,:col] = rot180(im[:row,:col])\n",
    "        im[:row,col:] = rot180(im[:row,col:])\n",
    "        im[row:,:col] = rot180(im[row:,:col])\n",
    "        im[row:,col:] = rot180(im[row:,col:])\n",
    "\n",
    "        return im\n",
    "    \n",
    "    def get_layer_by_name_with_functionals(self, name, model=None):\n",
    "        if model is None:\n",
    "            model = self\n",
    "        \n",
    "        l_list = self._get_layer_by_name_with_functionals(name, model)\n",
    "    \n",
    "        if l_list is None:\n",
    "            raise ValueError('Layer not found.')\n",
    "        else:\n",
    "            return l_list + [model]\n",
    "    \n",
    "    def _get_layer_by_name_with_functionals(self, name, model=None, _found_layer=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        return the layer with the desired exact name.\n",
    "        !!! Always give \"_found_layer=None\".\n",
    "        !!! Give \"model=None\" to search the current model. \n",
    "        \"\"\"\n",
    "        \n",
    "        for l in model.layers:\n",
    "            if '.Functional' in str(l):\n",
    "                \n",
    "                _found_layer = self._get_layer_by_name_with_functionals(name, l, _found_layer)\n",
    "                \n",
    "                if _found_layer:\n",
    "                    _found_layer += [l]\n",
    "                    break\n",
    "                \n",
    "            else:\n",
    "                if l.name==name:\n",
    "                    return [l]\n",
    "                \n",
    "        return _found_layer\n",
    "    \n",
    "    \n",
    "    def get_functional_input_name(self, layer, model=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns the inputs of \"layer\" within \"model\"\n",
    "        layer: the layer to analyze\n",
    "        model: the model where to search\n",
    "        \"\"\"\n",
    "        \n",
    "        if model is None:\n",
    "            model = self\n",
    "    \n",
    "        # type, or class name of the layer\n",
    "        l_class = str(type(layer)).split('.')[-1][:-2]\n",
    "        \n",
    "        # input layers have no inputs\n",
    "        if l_class=='InputLayer':\n",
    "            return []\n",
    "\n",
    "        # aggregates lines of text (read from summary)\n",
    "        def print_fn(x, summary):\n",
    "            summary += [x]\n",
    "\n",
    "        # initialize the variable storing the summary\n",
    "        summary = []\n",
    "        line_length = 200\n",
    "        \n",
    "        # store the summary in the variable \"summary\"\n",
    "        model.summary(line_length=line_length, print_fn=lambda x: print_fn(x, summary))\n",
    "        \n",
    "        ##### extract info from summary\n",
    "        \n",
    "        # the index at which inputs are listed\n",
    "        bias = summary[2].find('Connected to')\n",
    "        \n",
    "        # join all summary lines in one line\n",
    "        summary = ''.join(summary)\n",
    "        \n",
    "        # sequential model\n",
    "        if bias==-1:\n",
    "            \n",
    "            start_ind_inp = summary.find(f' {layer.name} ({l_class})')\n",
    "            for i in range(1, 10):\n",
    "                ind = start_ind_inp + 1 - i*line_length\n",
    "                if summary[ind]!=' ':\n",
    "                    return [summary[ind: summary.find(' (', ind)] + '[0][0]']\n",
    "                    \n",
    "            \n",
    "        else: # the model is not sequential\n",
    "                        \n",
    "            # finds the layer in the summary\n",
    "            start_ind_inp = summary.find(f' {layer.name} ({l_class})') + bias + 2\n",
    "\n",
    "            # if no inputs are used for this layer\n",
    "            if summary[start_ind_inp-1]==']':\n",
    "                inp_name_list = []\n",
    "\n",
    "            # if the layer has layers\n",
    "            else:\n",
    "                ##### search for the inputs\n",
    "                stop_ind_inp = summary.find(\"'\", start_ind_inp)\n",
    "                inp_name_list = [summary[start_ind_inp: stop_ind_inp]]\n",
    "\n",
    "                # search until all inputs are found\n",
    "                while summary[stop_ind_inp+1]==',':\n",
    "                    start_ind_inp += line_length\n",
    "                    stop_ind_inp = summary.find(\"'\", start_ind_inp)\n",
    "                    inp_name_list += [summary[start_ind_inp: stop_ind_inp]]\n",
    "            \n",
    "        return inp_name_list\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_list(x):\n",
    "        \n",
    "        \"\"\"\n",
    "        returns a list if the input is not a list\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(x) is not list:\n",
    "            x = [x]\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_list(x):\n",
    "        \n",
    "        \"\"\"\n",
    "        returns the element of a list that only has one element, \n",
    "        otherwise does nothing.\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(x) is list and len(x)==1:\n",
    "            x = x[0]\n",
    "        return x\n",
    "    \n",
    "    def _modify(self, model, modifier, layers_modified=None, name_target_layers=None,\n",
    "                name_outputs_to_remove=None, clone=False, keep_weights=False, \n",
    "                propagate_new_layer_outputs_to_model_output=False, index_propagation=None, **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        'model': the model where to use substitute the layer.\n",
    "        'modifier': operation to be done with the layer. Function of str.\n",
    "                    possible str keyword: \"add\", \"substitute\". The firts adds the layer\n",
    "        'layers_modified': layers that will substitute the layer with the same name.\n",
    "        'name_target_layers': the name of the layer in the model, that when found activates \"modifier\",\n",
    "                              if None it assumes the layer to search has the same name as \"layers_modified\"\n",
    "        'name_outputs_to_remove': the name of the outputs that will not be included in the model outputs.\n",
    "        'clone': whether to return an independent model or not. Dependent models share the weights.\n",
    "        'keep_weights': if model is clone, whether to keep the weights or re-initialize it.\n",
    "        'propagate_new_layer_outputs_to_model_output': whether to include the new layer output in the model output.\n",
    "        'index_propagation': what output to include. If None, all outputs of the layer are used.\n",
    "        'kwargs': used as inputs for modifier.\n",
    "        \"\"\"\n",
    "\n",
    "        if layers_modified is None and name_target_layers is None:\n",
    "            raise ValueError('specity \"name_taget_layers\", or provide \"layers_modified\" ',\n",
    "                             'and their name will be used as target layers names')\n",
    "        \n",
    "        if type(modifier)==str:\n",
    "            if modifier not in ['add', 'addition', 'substitute', 'substitution']:\n",
    "                raise ValueError('enter a valid modifier key words, or eneter a valid modifier function.',\n",
    "                                 'valid keywords: \"add\", \"substitute\".')\n",
    "        \n",
    "        if name_outputs_to_remove is None:\n",
    "            name_outputs_to_remove = []\n",
    "        \n",
    "        # check if modifier is a keywork and retrieve the modifier from default ones.\n",
    "        if modifier=='substitute' or modifier=='substitution':\n",
    "            modifier = self.modifier_substitute_layer\n",
    "        elif modifier=='add' or modifier=='addition':\n",
    "            modifier = self.modifier_add_layer\n",
    "        \n",
    "        # adjust data types.\n",
    "        layers_modified = self.to_list(layers_modified)\n",
    "        if index_propagation is not None:\n",
    "            index_propagation = self.to_list(index_propagation)\n",
    "        \n",
    "        # names of layers to substitue\n",
    "        if name_target_layers is None:\n",
    "            name_target_layers = [o.name for o in layers_modified]\n",
    "\n",
    "        # get the input names of all the layers in the model\n",
    "        dict_input = {}\n",
    "        for l in model.layers:\n",
    "            # get input name of one layer\n",
    "            dict_input[l.name] = self.get_functional_input_name(l, model)\n",
    "        \n",
    "            \n",
    "        _names_all_inputs = [i for j in dict_input.values() for i in j]\n",
    "        \n",
    "        # remove duplicated from list\n",
    "        names_all_inputs = []\n",
    "        [names_all_inputs.append(n) for n in _names_all_inputs if n not in names_all_inputs]\n",
    "        \n",
    "        # list containing the name of the model outputs\n",
    "        # initialize the list with the name of original outputs\n",
    "        final_output_name_list = [o.name for o in self.to_list(model.output) \n",
    "                                  if o.name not in name_outputs_to_remove]\n",
    "        \n",
    "        \n",
    "        # dict containing outputs of all layers indexed by layer name\n",
    "        dict_tensors = {}\n",
    "        \n",
    "        # dict containing outputs of all layers indexed by output name\n",
    "        dict_model_output = {}\n",
    "        \n",
    "        # gather all inputs\n",
    "        list_model_inputs = []\n",
    "        \n",
    "        # loop over all layers of model\n",
    "        for l in model.layers:\n",
    "            \n",
    "            # type, or class name, of the layer\n",
    "            l_class = str(type(l)).split('.')[-1][:-2]\n",
    "\n",
    "            # if the layer is an InputLayer no need for an input\n",
    "            if l_class=='InputLayer':\n",
    "                outputs_l = self.to_list(l.output)\n",
    "                list_model_inputs += outputs_l\n",
    "                \n",
    "                # loop over all outputs of the input layer (usually just one)\n",
    "                for j, o in enumerate(outputs_l):\n",
    "                    \n",
    "                    dict_tensors[f'{l.name}[0][{j}]'] = o\n",
    "                    dict_model_output[o.name] = o\n",
    "                    \n",
    "            # if layer is not an InputLayer\n",
    "            else:\n",
    "                \n",
    "                ##### handle multiple calls of the same layer by creating multiple inputs\n",
    "                # index of the number of times the layer is called\n",
    "                i = -1\n",
    "                \n",
    "                # all inputs of the layer; inputs are removed the when used \n",
    "                # next layer is considered when all inputs have been used\n",
    "                _input_name_list = dict_input[l.name]\n",
    "                \n",
    "                # store all inputs ordered in sublists; every sublist is for a \n",
    "                # single call of the layer \n",
    "                output_name_list = []\n",
    "                \n",
    "                # loop until all inputs have been used\n",
    "                while _input_name_list:\n",
    "                    \n",
    "                    # initialize the sublist of inputs for a single layer call\n",
    "                    output_name_sublist = []\n",
    "                    \n",
    "                    # update the index of the layer call\n",
    "                    i = i+1\n",
    "                    \n",
    "                    # loop over all inputs that have been used yet\n",
    "                    for _o in _input_name_list:\n",
    "                        \n",
    "                        # if an input is the result of this current layer call at a further iteration\n",
    "                        # or it has already been considered, the sublist is completed. Go to next call\n",
    "                        if _o.find(f'{l.name}[{i}]')>=0 or _o in output_name_sublist:\n",
    "                            break\n",
    "                        \n",
    "                        # add input to current sublist\n",
    "                        output_name_sublist += [_o]\n",
    "                    \n",
    "                    # store sublist\n",
    "                    output_name_list += [output_name_sublist]\n",
    "                    \n",
    "                    # remove used inputs from list\n",
    "                    [_input_name_list.remove(r) for r in output_name_sublist]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                ##### call layer\n",
    "                # (handles multiple layer calls)\n",
    "                \n",
    "                # loop over all input sublists (usually len=1; len>1 if multiple calls).\n",
    "                for i, output_name in enumerate(output_name_list):\n",
    "                    \n",
    "                    inputs_l = [dict_tensors[o_name] for o_name in output_name]                \n",
    "                                        \n",
    "                    # check if the layer is the target one\n",
    "                    if l.name in name_target_layers:\n",
    "                        \n",
    "                        # first layer call\n",
    "                        if i==0:\n",
    "                            # get new layer\n",
    "                            l_modified = layers_modified[name_target_layers.index(l.name)]\n",
    "                        \n",
    "                        outputs_l, final_output_name_list = modifier(\n",
    "                            l, inputs_l, l_modified, i, len(output_name_list)-1, \n",
    "                            propagate_new_layer_outputs_to_model_output,\n",
    "                            final_output_name_list, index_propagation, **kwargs)\n",
    "                    \n",
    "                    else:\n",
    "                        # call the layer and get results\n",
    "                        outputs_l = self.to_list(l(self.from_list(inputs_l)))\n",
    "                    \n",
    "                    ##### store outputs\n",
    "                    # loop over all layer outputs\n",
    "                    for j, o in enumerate(outputs_l):\n",
    "                        \n",
    "                        # handle previous multi layer calls, by storing tensors with correct index.\n",
    "                        # implementation: search in the list of all inputs what is the first missing\n",
    "                        \n",
    "                        str_0, str_1 = f'{l.name}[', f'][{j}]'\n",
    "                        len_0, len_1 = len(str_0), len(str_1)\n",
    "                        \n",
    "                        list_tmp = [n for n in names_all_inputs if (n[:len_0]==str_0 and n[-len_1:]==str_1)]\n",
    "                        \n",
    "                        # this tensor is used as an input\n",
    "                        if list_tmp!=[]:\n",
    "                            \n",
    "                            index_l_call = min([int(n[len_0: n.find(']', len_0)]) for n in list_tmp])\n",
    "\n",
    "                            \n",
    "                            dict_tensors[f'{l.name}[{index_l_call}][{j}]'] = o\n",
    "                            \n",
    "                            # update the list of missing input tensors names\n",
    "                            for n in names_all_inputs:\n",
    "                                if (n[:len_0]==str_0 and f'[{index_l_call}]' in n[len_0-1:-len_1+1] and n[-len_1:]==str_1):\n",
    "                                    names_all_inputs.remove(n)\n",
    "                        \n",
    "                        # store layer outputs\n",
    "                        dict_model_output[o.name] = o\n",
    "                        \n",
    "            pass\n",
    "        \n",
    "        # new outputs\n",
    "        outputs_model = [dict_model_output[o_name] for o_name in final_output_name_list]\n",
    "\n",
    "        ##### order the inputs as the original model\n",
    "        original_input_name = [i.name for i in model.inputs]\n",
    "        list_model_input_name = [i.name for i in list_model_inputs]\n",
    "        list_model_inputs_ordered = list_model_input_name\n",
    "        for i in list_model_inputs:\n",
    "            ind = original_input_name.index(i.name)\n",
    "            list_model_inputs_ordered[ind] = i\n",
    "            \n",
    "        # create the model with new outputs\n",
    "        model = type(model)(list_model_inputs_ordered, outputs_model, name=model.name)\n",
    "        \n",
    "\n",
    "        # clone and preserve weights\n",
    "        if clone==True:\n",
    "            if keep_weights==True:\n",
    "                w_old = model.get_weights()\n",
    "            model = tf.keras.models.clone_model(model)\n",
    "\n",
    "            if keep_weights==True:\n",
    "                model.set_weights(w_old)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def modifier_substitute_layer(self, \n",
    "                                  l,\n",
    "                                  inputs, \n",
    "                                  layer_modified, \n",
    "                                  index_call=0,\n",
    "                                  max_index_call=0, \n",
    "                                  propagate_new_layer_outputs_to_model_output=False,\n",
    "                                  final_output_name_list=None,\n",
    "                                  index_propagation=None,):\n",
    "        \n",
    "        if propagate_new_layer_outputs_to_model_output and final_output_name_list is None:\n",
    "            raise ValueError('provide \"final_output_name_list\" if propagate outputs is active.')\n",
    "\n",
    "        # call the layer and get results\n",
    "        outputs = self.to_list(layer_modified(self.from_list(inputs)))\n",
    "\n",
    "        # last layer call\n",
    "        if index_call==max_index_call and propagate_new_layer_outputs_to_model_output:\n",
    "\n",
    "            # include new layer outputs to model output (not if already included)\n",
    "            name_o = [o.name for o in outputs if o.name not in final_output_name_list]\n",
    "\n",
    "            # check which outputs to include based on user specification\n",
    "            if index_propagation is not None:\n",
    "                name_o = [n for ind, n in enumerate(name_o) if ind in index_propagation]\n",
    "            \n",
    "            final_output_name_list += name_o\n",
    "            \n",
    "        return outputs, final_output_name_list\n",
    "    \n",
    "    def modifier_add_layer(self, \n",
    "                           l,\n",
    "                           inputs, \n",
    "                           layer_modified, \n",
    "                           index_call=0,\n",
    "                           max_index_call=0, \n",
    "                           propagate_new_layer_outputs_to_model_output=False,\n",
    "                           final_output_name_list=None,\n",
    "                           index_propagation=None,):\n",
    "        \n",
    "        if propagate_new_layer_outputs_to_model_output and final_output_name_list is None:\n",
    "            raise ValueError('provide \"final_output_name_list\" if propagate outputs is active.')\n",
    "        \n",
    "        # call the layer and get results\n",
    "        outputs = self.to_list(l(self.from_list(inputs)))\n",
    "\n",
    "        # last layer call\n",
    "        if index_call==max_index_call:\n",
    "            \n",
    "            old_output_shape = [o.shape for o in outputs]\n",
    "                        \n",
    "            outputs = self.to_list(layer_modified(self.from_list(outputs)))\n",
    "            \n",
    "            new_outputs_shape = [o.shape for o in outputs]\n",
    "            \n",
    "            # check compatibility of the new layer (matching number of outputs and shapes)\n",
    "            _and = lambda x, y: a & y\n",
    "            if len(new_outputs_shape)<len(old_outputs_shape):\n",
    "                \n",
    "                # the first outputs of the new layer must have same shape as the outputs of previous layer,\n",
    "                # The new layer may have more outputs than the previous layer, but compatibility is not affceted.\n",
    "                seq_shape = [i==j for i, j in zip(old_outputs_shape, new_outputs_shape)]\n",
    "                if not (functools.reduce(_and, seq_shape)):\n",
    "                    raise ShapeError('The new layer must have the same number of outputs as its previous layer. ',\n",
    "                                     'Also, the shapes of all the new and previous layer outputs must match.')\n",
    "                \n",
    "            if propagate_new_layer_outputs_to_model_output:\n",
    "\n",
    "                # include new layer outputs to model output, if not already included\n",
    "                name_o = [o.name for o in outputs if o.name not in final_output_name_list]\n",
    "\n",
    "                # check which outputs to include based on user specification (if provided)\n",
    "                if index_propagation is not None:\n",
    "                    name_o = [n for ind, n in enumerate(name_o) if ind in index_propagation]\n",
    "\n",
    "                final_output_name_list += name_o\n",
    "            \n",
    "        return outputs, final_output_name_list\n",
    "        \n",
    "    \n",
    "    \n",
    "    def propagate_layer_outputs(self,\n",
    "                                name_layer,\n",
    "                                index_propagation=None,\n",
    "                                keep_old_outputs=True,\n",
    "                                clone=False,\n",
    "                                keep_weights=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        Takes the outputs of \"layer\" and propagates them through \n",
    "        the nested sequence of layers till they become outputs of the model.\n",
    "        \n",
    "        Args:\n",
    "            name_layer: list of layer names whose outputs will be propagated\n",
    "            model: the model where to search the layer. If None, this istance is used\n",
    "            index_propagation: select which outputs to propagate by indexing. If None, all outputs are taken\n",
    "            keep_old_outputs: whether to keep or remove original outputs\n",
    "            clone: whether to return a deep dopy or not\n",
    "            keep weights: if \"clone==True\", whether it mantains the same weights as the original model.\n",
    "        Outputs:\n",
    "            A model with new propagated outputs, the same type as the input model.\n",
    "        \"\"\"\n",
    "        \n",
    "        name_old_outputs = None\n",
    "        if not keep_old_outputs:\n",
    "            name_old_outputs = [o.name for o in self.outputs]\n",
    "        \n",
    "        return self.modify_model(name_layer, 'substitute', self, True, \n",
    "                                 name_old_outputs,\n",
    "                                 index_propagation, clone, keep_weights)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def modify_model(self,\n",
    "                     name_target_layers,\n",
    "                     modifier,\n",
    "                     model=None,\n",
    "                     propagate_outputs=False,\n",
    "                     name_outputs_to_remove=None,\n",
    "                     index_propagation=None,\n",
    "                     clone=False,\n",
    "                     keep_weights=False, \n",
    "                     **kwargs):\n",
    "\n",
    "        \"\"\"\n",
    "        name_target_layers: when the layer with this name is found, the modifier acts\n",
    "        modifier: action to take. Can be a function or can be a keyword: \"add\" or \"substitute\".\n",
    "        model: if None, self is used\n",
    "        propagate_outputs: whether to propagate the outputs of the selected layer of not\n",
    "        name_outputs_to_remove: list of names of the outputs of the model to remove\n",
    "        index_propagation: if layers have multiple outputs and certain should be considered, e.g., [[0, 4], [1]]\n",
    "        clone: whether to return an independent model or not. Dependent models share the weights.\n",
    "        keep_weights: if model is clone, whether to keep the weights or re-initialize it.\n",
    "        \"\"\"\n",
    "\n",
    "        # handle index propagation\n",
    "        if propagate_outputs:\n",
    "            if index_propagation is not None:\n",
    "                index_propagation = self.to_list(index_propagation)\n",
    "                if len(index_propagation)!=len(name_target_layers):\n",
    "                    raise ValueError('index_propagation is a list of lists with len equal to name_target_layers')\n",
    "            else:\n",
    "                index_propagation = [index_propagation]*len(name_target_layers)\n",
    "                \n",
    "        name_target_layers = self.to_list(name_target_layers)\n",
    "        \n",
    "        if model is None:\n",
    "            model = self\n",
    "            \n",
    "        _name_outputs_to_remove = None\n",
    "        \n",
    "        for i, (n_target, ind_prop) in enumerate(zip(name_target_layers, index_propagation)):\n",
    "\n",
    "            # layer path to the specified layer\n",
    "            l_list = model.get_layer_by_name_with_functionals(n_target)\n",
    "            \n",
    "            model = self._modify(\n",
    "                l_list[1], modifier, l_list[0], n_target, \n",
    "                name_outputs_to_remove=None,\n",
    "                propagate_new_layer_outputs_to_model_output=propagate_outputs, \n",
    "                index_propagation=ind_prop,\n",
    "                **kwargs)\n",
    "            \n",
    "            name_m_outputs = [o.name for o in model.outputs]\n",
    "            name_l_outputs = [o.name for o in self.to_list(l_list[0].output)]\n",
    "            ind_prop = [name_m_outputs.index(nl) for nl in name_l_outputs]\n",
    "            \n",
    "            for j, l in enumerate(l_list[2:]):\n",
    "\n",
    "                if i==len(name_target_layers)-1 and j==len(l_list[2:])-1:\n",
    "                    _name_outputs_to_remove = name_outputs_to_remove\n",
    "\n",
    "                model = self._modify(\n",
    "                    l, 'substitute', model, name_outputs_to_remove=_name_outputs_to_remove, \n",
    "                    propagate_new_layer_outputs_to_model_output=propagate_outputs,\n",
    "                    index_propagation=index_propagation)\n",
    "                \n",
    "                name_m_outputs = [o.name for o in model.outputs]\n",
    "                name_l_outputs = [o.name for o in self.to_list(l.output)]\n",
    "                index_propagation = [name_m_outputs.index(nl) for nl in name_l_outputs]\n",
    "                    \n",
    "            pass\n",
    "        \n",
    "        # clone the model\n",
    "        if clone==True:\n",
    "            \n",
    "            if keep_weights==True:\n",
    "                w = model.get_weights()\n",
    "                pass\n",
    "            \n",
    "            model = tf.keras.models.clone_model(model)\n",
    "            if keep_weights==True:\n",
    "                model.set_weights(w)\n",
    "            pass\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6440075b-23ce-4830-a00a-d56840f53388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model_enc_dec(Model_with_layer_search):\n",
    "    \n",
    "    \"\"\"\n",
    "    A class for incremental MRI\n",
    "    \n",
    "    It has the Dykstra and the Masker included\n",
    "    You can add the self-assessment to it\n",
    "    You can get a model with all the desired sub-results (or default)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 inputs=None,\n",
    "                 outputs=None,\n",
    "                 input_shape=None,\n",
    "                 R=None,\n",
    "                 masker=None,\n",
    "                 sequence_type='unconstrained', \n",
    "                 iterations_dykstra=10,\n",
    "                 data_augmentation=False,\n",
    "                 mode='train',\n",
    "                 name='enc_dec',\n",
    "                 **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        If you have already have the model structure, provide \"inputs\" and \"outputs\",\n",
    "        otherwise provide \"R\" and \"masker\" and the standard architecture is used.\n",
    "        \n",
    "        The masker and the mask have lower freq in the centre. \n",
    "        The keras model works with lower freq in the corners, so setter and getter are used.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if ((inputs is None or outputs is None) and input_shape is None):\n",
    "            raise ValueError('provide a model structure with \"inputs\" and \"outputs\" ',\n",
    "                             'or provide at least \"input_shape\", and the structure is created inside')\n",
    "        \n",
    "        if mode != 'train' and mode != 'test':\n",
    "            raise ValueError('mode can take only \"train\" or \"test\"')\n",
    "            \n",
    "        if inputs is None or outputs is None:            \n",
    "            # make sure masker is compliant\n",
    "            if masker is not None:\n",
    "                masker = self.rotate_corners(np.array(masker))\n",
    "                \n",
    "            if R is None:\n",
    "                R=1.0\n",
    "            \n",
    "            inputs, outputs = self.get_model_structure(\n",
    "                input_shape,\n",
    "                R,\n",
    "                masker,\n",
    "                sequence_type, \n",
    "                iterations_dykstra,\n",
    "                data_augmentation)\n",
    "            \n",
    "        super(Model_enc_dec, self).__init__(inputs, outputs, name=name, **kwargs)\n",
    "                \n",
    "        self.mode = mode\n",
    "        self.data_augmentation = data_augmentation\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    @property\n",
    "    def R(self):\n",
    "        return self.get_layer_by_name('prob_mask_scaled').R\n",
    "    @R.setter\n",
    "    def R(self, R):\n",
    "        self.get_layer_by_name('prob_mask_scaled').R = tf.cast(R, tf.float32)\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def sequence_type(self,):\n",
    "        return self.get_layer_by_name('prob_mask').sequence_type\n",
    "    @sequence_type.setter\n",
    "    def sequence_type(self, sequence_type):\n",
    "        self.get_layer_by_name('prob_mask').sequence_type = sequence_type\n",
    "        self.get_layer_by_name('random_mask').sequence_type = sequence_type\n",
    "        pass\n",
    "    \n",
    "    # handle inner masker representation\n",
    "    @property\n",
    "    def masker(self):\n",
    "        masker = self.get_layer_by_name('masker').read_masker()\n",
    "        return self.rotate_corners(np.array(masker))\n",
    "    @masker.setter\n",
    "    def masker(self, masker):\n",
    "        masker = self.rotate_corners(np.array(masker))\n",
    "        self.get_layer_by_name('masker').write_masker(masker)\n",
    "        pass\n",
    "    \n",
    "    # handle probability mask inner mask representation\n",
    "    @property\n",
    "    def prob_mask(self):\n",
    "        \"\"\"\n",
    "        Returns the probability mask (values from 0 to 1).\n",
    "        To get the real value prob_mask (before sigmoid) get to the layer \"prob_mask\"\n",
    "        then call the method \"layer.read_probMask(True)\"\n",
    "        \"\"\"\n",
    "        prob_mask = self.get_layer_by_name('prob_mask').read_probMask()\n",
    "        return self.rotate_corners(np.array(prob_mask))\n",
    "    @prob_mask.setter\n",
    "    def prob_mask(self, prob_mask):\n",
    "        \"\"\"\n",
    "        Set the probability mask by taking the probality mask (values from 0 to 1).\n",
    "        To set the real valued (before sigmoid) prob_mask use the layer method \n",
    "        \"layer.read_probMask(True)\".\n",
    "        \"\"\"\n",
    "        prob_mask = self.rotate_corners(np.array(prob_mask))\n",
    "        self.get_layer_by_name('prob_mask').set_probMask(prob_mask)\n",
    "        pass\n",
    "    \n",
    "    # handle inner mask representation\n",
    "    @property\n",
    "    def mask(self):\n",
    "        mask = np.array(self.prob_mask)>0.5\n",
    "        masker = np.array(self.masker)\n",
    "        return mask*masker\n",
    "    @mask.setter\n",
    "    def mask(self, mask):\n",
    "        raise ValueError('to be programmed')\n",
    "        # take the mask and retrieve the model parameters to retrieve the prob_mask\n",
    "        # then set the prob_mask\n",
    "        pass\n",
    "    \n",
    "    # prevent wrong mode assignement\n",
    "    @property\n",
    "    def mode(self):\n",
    "        return self._mode\n",
    "    @mode.setter\n",
    "    def mode(self, mode):\n",
    "        self.set_mode(mode)\n",
    "        pass\n",
    "    \n",
    "    # retrieve model inputs and outputs\n",
    "    @staticmethod\n",
    "    def get_model_structure(input_shape,\n",
    "                            R,\n",
    "                            masker=None,\n",
    "                            sequence_type='unconstrained', \n",
    "                            iterations_dykstra=10, \n",
    "                            data_augmentation=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        static method\n",
    "        \n",
    "        Get the stanrdard accelerated MRI autoencoder structure, i.e., inputs and outputs.\n",
    "        if masker is None, then it is all 1, e.i, is an irrelevant layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # input\n",
    "        tensor_input = tf.keras.Input(input_shape, name='input_enc_dec')\n",
    "        \n",
    "        tensor = tensor_input\n",
    "        \n",
    "        # data augmentation\n",
    "        if data_augmentation:\n",
    "            submodel_augmentation = models.data_augmentation(input_shape)\n",
    "            tensor = submodel_augmentation(tensor)\n",
    "        \n",
    "        # enc\n",
    "        submodel_enc = models.enc_mri(input_shape,\n",
    "                                      R,\n",
    "                                      masker=masker,\n",
    "                                      sequence_type=sequence_type)\n",
    "        tensor_mask, tensor_z = submodel_enc(tensor)\n",
    "\n",
    "        # dec\n",
    "        submodel_dec = models.dec_mri(tensor_z.shape[1:])\n",
    "        tensor_x_bar = submodel_dec(tensor_z)\n",
    "\n",
    "        # measurement constraint + Dykstra\n",
    "        submodel_mc = models.measure_constraint_mri(tensor_x_bar.shape[1:],\n",
    "                                                    tensor_mask.shape[1:],\n",
    "                                                    iterations_dykstra)\n",
    "        tensor_x_hat = submodel_mc([tensor_x_bar, tensor_z, tensor_mask])\n",
    "        \n",
    "        tensor_output = tensor_x_hat\n",
    "        \n",
    "        # data augmentation\n",
    "        if data_augmentation:\n",
    "            submodel_mae = models.mae_standard(tensor.shape[1:])\n",
    "            tensor_output = submodel_mae([tensor, tensor_output])\n",
    "            \n",
    "        return tensor_input, tensor_output\n",
    "    \n",
    "    # whetehr model should be trained or tested\n",
    "    def set_mode(self, mode):\n",
    "        \"\"\"\n",
    "        mode can take \"train\" or \"test\", \n",
    "        if \"mode==train\" masks are random and undersampling is with soft threshold;\n",
    "        if \"mode==test\" masks are fixed and undersampling is with hard threhsold.\n",
    "        \"\"\"\n",
    "        \n",
    "        if mode!=\"train\" and mode!=\"test\":\n",
    "            raise ValueError('mode can take \"test\" or \"train\"')\n",
    "        \n",
    "        if mode=='test':\n",
    "            maxval = 0.50000001\n",
    "            minval = 0.49999999\n",
    "            hard_threshold = True\n",
    "        else:\n",
    "            maxval = 1\n",
    "            minval = 0\n",
    "            hard_threshold = False\n",
    "\n",
    "        self._set_mode_recursive(self, maxval, minval, hard_threshold)\n",
    "        self._mode = mode\n",
    "        pass\n",
    "    \n",
    "    def _set_mode_recursive(self, model, maxval, minval, hard_threshold):\n",
    "        \n",
    "        \"\"\"\n",
    "        !!! It is safer to call this function via the method \"set_mode(...)\"\n",
    "        Recursively checks all the layers of the model and sets 1) all \"random_mask\" layers\n",
    "        attributes \"maxval\" and \"minval\"; 2) all \"undersample\" layers attributes\n",
    "        \"hard_threshold\".\n",
    "        \"\"\"\n",
    "        \n",
    "        for l in model.layers:\n",
    "            if not('.Functional' in str(l)):\n",
    "                if 'random_mask' in l.name:\n",
    "                    l.set_attributes(maxval = maxval, minval = minval)\n",
    "\n",
    "                elif 'undersample' in l.name:\n",
    "                    l.set_attributes(hard_threshold = hard_threshold)\n",
    "            else:\n",
    "                self._set_mode_recursive(l, maxval, minval, hard_threshold)\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def fit_safe(self, x, y, mode='train', **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        Normal \"fit\" function, but the new arg \"mode\" lets the user specify the mode.\n",
    "        \"\"\"\n",
    "        \n",
    "        if mode!='current' and self.mode!=mode:\n",
    "            self.mode=mode\n",
    "        return super(Model_enc_dec, self).fit(x, y, **kwargs)\n",
    "    \n",
    "    def evaluate_safe(self, x, y, mode='test', **kwargs):\n",
    "        if self.mode!=mode:\n",
    "            self.mode=mode\n",
    "        return super(Model_enc_dec, self).evaluate(x, y, **kwargs)\n",
    "    \n",
    "    def predict_safe(self, x, mode='test', **kwargs):\n",
    "        if self.mode!=mode:\n",
    "            self.mode=mode\n",
    "        return super(Model_enc_dec, self).predict(x, **kwargs)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0c363d-3ebd-4187-a3b6-ea89b4583695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_self_assessment(Model_with_layer_search):\n",
    "    \n",
    "    \"\"\"\n",
    "    A self assessment class for incremental MRI.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 inputs=None,\n",
    "                 outputs=None,\n",
    "                 input_shape=None,\n",
    "                 name='self_assessment',\n",
    "                 line_coef=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        If you have already have the model structure, provide \"inputs\" and \"outputs\",\n",
    "        otherwise provide \"input_shape\", in the form of the original image shape.\n",
    "        \"\"\"\n",
    "        \n",
    "        if ((inputs is None or outputs is None) and input_shape is None):\n",
    "            raise ValueError('provide a model structure with \"inputs\" and \"outputs\" ',\n",
    "                             'or provide at least \"input_shape\", and the structure is created inside')\n",
    "        \n",
    "        if inputs is None or outputs is None:\n",
    "            \n",
    "            inputs, outputs = self.get_model_structure(\n",
    "                input_shape[:-1]+(2,),\n",
    "                input_shape, \n",
    "                line_coef=line_coef)            \n",
    "            \n",
    "        super(Model_self_assessment, self).__init__(inputs, outputs, name=name, **kwargs)\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_line_coef(pred, true, poly_degree, higher_degree_first=True):\n",
    "        \n",
    "        coef = np.polyfit(pred, true, poly_degree)[::-1]\n",
    "        \n",
    "        if higher_degree_first:\n",
    "            coef = coef[::-1]\n",
    "        \n",
    "        return coef\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_model_structure(input_shape_z,\n",
    "                            input_shape_x,\n",
    "                            line_coef=None,\n",
    "                            filt=[10,8,6,4,2,1],\n",
    "                            kern=[5]*6,\n",
    "                            pool_size=[(2, 2)]*6,\n",
    "                            average_pooling=True,\n",
    "                            poly_degree=2,\n",
    "                            name='self_assessment'):\n",
    "        \n",
    "        \"\"\"\n",
    "        if inputs=[tensor_z, tensor_x_bar, tensor_x_hat, tensor_m] is provided it is used,\n",
    "        if it not provided, the shapes are used to create new tensor inputs.\n",
    "        \"\"\"\n",
    "\n",
    "        tensor_z = tf.keras.Input(input_shape_z, name='input_z')\n",
    "        tensor_x_bar = tf.keras.Input(input_shape_z, name='input_x_bar')\n",
    "        tensor_x_hat = tf.keras.Input(input_shape_x, name='input_x_hat')\n",
    "        tensor_m = tf.keras.Input(input_shape_x, name='input_mask')\n",
    "        \n",
    "        inputs = [tensor_z, tensor_x_bar, tensor_x_hat, tensor_m]\n",
    "        \n",
    "        # mae\n",
    "        submodel_mae = models.mae_mri(input_shape_z, input_shape_x, layer_x_mod='fft')\n",
    "        tensor_mae = submodel_mae([tensor_z, tensor_m, tensor_x_bar])    \n",
    "        \n",
    "        # self-assessment\n",
    "        submodel_self_assessment = models.model_self_assessment(\n",
    "                input_shape_x, \n",
    "                tensor_mae.shape[1:],\n",
    "                line_coeff=line_coef,\n",
    "                filt=filt,\n",
    "                kern=kern,\n",
    "                pool_size=pool_size,\n",
    "                average_pooling=average_pooling,\n",
    "                poly_degree=poly_degree,\n",
    "                name=name,\n",
    "            )\n",
    "        tensor_q = submodel_self_assessment([tensor_x_hat, tensor_mae])\n",
    "        \n",
    "        return [tensor_z, tensor_x_bar, tensor_x_hat, tensor_m], tensor_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6249929-a3fa-42a4-afa5-8a9328beebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manager_incremental():\n",
    "    \n",
    "    \"\"\"\n",
    "    Stores important path for Incremental training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 working_dir,\n",
    "                 dataset,\n",
    "                 sequence_type,\n",
    "                 R_list,\n",
    "                 R=None,\n",
    "                 redundancy=0,\n",
    "                 incremental_id=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        R_list: list of all R to be used in incremental.\n",
    "        get_model_enc_dec: function to get the model for undersampling and reconstructing.\n",
    "        get_model_self_assessment: function to get the model for quality estimation.\n",
    "        redundancy: number of models to train contemporarily (only best is kept).\n",
    "        \"\"\"\n",
    "        \n",
    "        if sequence_type not in ['unconstrained', 'cartesian_rows', 'cartesian_columns']:\n",
    "            raise ValueError(\"'sequence_type' is not valid. Enter one between\",\n",
    "                             \" 'unconstrained', 'cartesian_rows', 'cartesian_columns'.\")\n",
    "            \n",
    "        if incremental_id is None:\n",
    "            incremental_id = ''\n",
    "            \n",
    "        if R is None:\n",
    "            R = R_list[0]\n",
    "            \n",
    "        self.id = self.get_id(dataset, sequence_type, incremental_id)\n",
    "        \n",
    "        self.working_dir = working_dir\n",
    "        self.dataset = dataset\n",
    "        self.R_list = np.sort(R_list)\n",
    "        self.R = R\n",
    "        self.sequence_type = sequence_type\n",
    "        self.redundancy = redundancy\n",
    "        self.incremental_id = incremental_id\n",
    "        \n",
    "        self.create_path()\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_id(dataset, sequence_type, incremental_id):\n",
    "        if incremental_id!='' and incremental_id[0]!='-':\n",
    "            incremental_id = '-'+incremental_id\n",
    "        return f'{dataset}-{sequence_type}{incremental_id}'\n",
    "    \n",
    "    def create_path(self,):\n",
    "        \n",
    "        for R_tmp in R_list:\n",
    "            path_R = self.get_main_path(R_tmp)\n",
    "            \n",
    "            for model_str in ['enc_dec', 'self_assessment']:\n",
    "                \n",
    "                os.makedirs(os.path.join(path_R, model_str, 'weights'), exist_ok=True)\n",
    "                \n",
    "                for i in range(self.redundancy+1):\n",
    "                    for j in ['tensorboard', os.path.join('checkpoint', 'checkpoint.ckpt')]:\n",
    "                        os.makedirs(os.path.join(path_R, model_str, f'redundancy_{i}', j), exist_ok=True)\n",
    "                \n",
    "        pass\n",
    "    \n",
    "    def get_main_path(self, R):\n",
    "        return os.path.join(self.working_dir, self.id, str(R))\n",
    "    \n",
    "    # R\n",
    "    @property\n",
    "    def R(self, ):\n",
    "        return self._R\n",
    "    @R.setter\n",
    "    def R(self ,R):\n",
    "        if R not in self.R_list:\n",
    "            raise ValueError('R must be in R_list')\n",
    "        self._R = R\n",
    "        pass\n",
    "    \n",
    "    # main_path\n",
    "    @property\n",
    "    def main_path(self):\n",
    "        return self.get_main_path(self.R)\n",
    "    \n",
    "    # main_path for ed or sa\n",
    "    @property\n",
    "    def path_ed(self):\n",
    "        return os.path.join(self.get_main_path(self.R), 'enc_dec')\n",
    "    @property\n",
    "    def path_sa(self):\n",
    "        return os.path.join(self.get_main_path(self.R), 'self_assessment')\n",
    "    \n",
    "    # weights\n",
    "    @property\n",
    "    def path_ed_weights(self):\n",
    "        return os.path.join(self.path_ed, 'weights')\n",
    "    @property\n",
    "    def path_sa_weights(self):\n",
    "        return os.path.join(self.path_sa, 'weights')\n",
    "    \n",
    "    \n",
    "    def check_index_redundancy(self, index_redundancy):\n",
    "        if index_redundancy is None and self.redundancy==0:\n",
    "            i = 0 \n",
    "        elif index_redundancy>=0 and index_redundancy<=self.redundancy:\n",
    "            i = index_redundancy\n",
    "        else:\n",
    "            raise ValueError('\"index_redundancy\" is not valid.')\n",
    "        return i\n",
    "    \n",
    "    # tensorboard\n",
    "    def get_path_ed_tensorboard(self, index_redundancy=0):\n",
    "        i = self.check_index_redundancy(index_redundancy)\n",
    "        return os.path.join(self.path_ed, f'redundancy_{i}', 'tensorboard')\n",
    "    def get_path_sa_tensorboard(self, index_redundancy=0):\n",
    "        i = self.check_index_redundancy(index_redundancy)\n",
    "        return os.path.join(self.path_sa, f'redundancy_{i}', 'tensorboard')\n",
    "\n",
    "    # checkpoint\n",
    "    def get_path_ed_checkpoint(self, index_redundancy=None):\n",
    "        i = self.check_index_redundancy(index_redundancy)\n",
    "        return os.path.join(self.path_ed, f'redundancy_{i}', 'checkpoint', 'checkpoint.ckpt')\n",
    "    def get_path_sa_checkpoint(self, index_redundancy=0):\n",
    "        i = self.check_index_redundancy(index_redundancy)\n",
    "        return os.path.join(self.path_sa, f'redundancy_{i}', 'checkpoint', 'checkpoint.ckpt')\n",
    "    \n",
    "    def get_callbacks(self, \n",
    "                      model_str, \n",
    "                      index_redundancy=None,\n",
    "                      factor_reduction_LR=0.2,\n",
    "                      patience_LR=40, \n",
    "                      patience_early=60,\n",
    "                      min_lr=1e-5):\n",
    "        \n",
    "        if model_str=='enc_dec':\n",
    "            path_checkpoint=self.get_path_ed_checkpoint(index_redundancy)\n",
    "            path_tensorboard=self.get_path_ed_tensorboard(index_redundancy)\n",
    "        elif model_str=='self_assessment':\n",
    "            path_checkpoint=self.get_path_sa_checkpoint(index_redundancy)\n",
    "            path_tensorboard=self.get_path_sa_tensorboard(index_redundancy)\n",
    "        else:\n",
    "            raise ValueError(\"'model_str' can only take 'enc_dec' or 'self_assessment'\")\n",
    "        \n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            \n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=factor_reduction_LR,\n",
    "                                                 patience=patience_LR,\n",
    "                                                 min_lr=min_lr),\n",
    "            \n",
    "            tf.keras.callbacks.EarlyStopping(patience=patience_early,\n",
    "                                             restore_best_weights=True),\n",
    "            \n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                               save_best_only=True,\n",
    "                                               save_weights_only=True),\n",
    "            \n",
    "            tf.keras.callbacks.TensorBoard(log_dir=path_tensorboard)]\n",
    "        \n",
    "        return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30da1801-8ec4-4183-9d1b-71cd8af2d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_edsa(Model_with_layer_search):\n",
    "\n",
    "    def __init__(self, ed, sa, metric='mae', alias_outputs_ed=None, alias_inputs_sa=None, name='sa_advanced', extended_ed=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Connects ed and sa models, useful for advanced sa training and for post-sa.\n",
    "        Args:\n",
    "            ed: a model for enc_dec, with all outputs necessary for connection with sa\n",
    "            sa: a model for self_assessment.\n",
    "            metric: the metric the \"sa\" predicts, that is computed on the fly and used as label.\n",
    "                    Avalilable keywords are \"mae\", \"mse\", \"ssim\". Otherwise pass a layer/model.\n",
    "            alias_outputs_ed: an alternative name for ed outputs (matching output order). \n",
    "                              Defoult, output names.\n",
    "                              It must contain \"x_hat\", i.e., the reconstructed image.\n",
    "            alias_inputs_sa: an alternative name for sa inputs (matching output order). \n",
    "                             Defoult, inputs names (prefix \"input_\" is automatically removed if present).\n",
    "            extended_ed: whether to use ed as a list of layers or as a functional. \n",
    "                         Set this to True for easier \"post_sa\"; Recommended: False.\n",
    "\n",
    "        The connections between ed and sa are created based on matching alias names.\n",
    "        \"\"\"\n",
    "        \n",
    "        input_shape = ed.inputs[0].shape[1:]\n",
    "        \n",
    "        if type(metric) is str:\n",
    "            if metric=='mae':\n",
    "                metric = models.mae_standard(input_shape)\n",
    "            elif metric=='mse':\n",
    "                metric = models.mse_standard(input_shape)\n",
    "            elif metric=='ssim':\n",
    "                metric = models.ssim_standard(input_shape)   \n",
    "            else:\n",
    "                raise ValueError('eneter a valid keyword: \"mae\", \"mse\" or \"ssim\".')\n",
    "        \n",
    "        self.extended_ed = extended_ed\n",
    "        \n",
    "        self.name_ed = ed.name\n",
    "        self.name_sa = sa.name\n",
    "\n",
    "        if alias_outputs_ed is None:\n",
    "            alias_outputs_ed = [o.name.split('/')[-2] for o in ed.outputs]\n",
    "\n",
    "        if alias_inputs_sa is None:\n",
    "            alias_inputs_sa = [i.name.replace('input_', '') for i in sa.inputs]\n",
    "            \n",
    "        if extended_ed:\n",
    "            inputs_ed = ed.inputs\n",
    "            outputs_ed = ed.outputs\n",
    "\n",
    "        else:\n",
    "            inputs_ed = tf.keras.Input(input_shape, name='input_edsa')\n",
    "            outputs_ed = ed(inputs_ed)\n",
    "            \n",
    "        # re-order outputs ed based on the order of input list of model sa\n",
    "        inputs_sa = [outputs_ed[alias_outputs_ed.index(a)]\n",
    "                     for a in alias_inputs_sa]\n",
    "            \n",
    "        # call self assessment \n",
    "        q_hat = sa(inputs_sa)\n",
    "\n",
    "        # get reconstructed image\n",
    "        x_hat = outputs_ed[alias_outputs_ed.index('x_hat')]\n",
    "\n",
    "        # assuming the input is the ground truth image\n",
    "        x = self.from_list(inputs_ed)\n",
    "\n",
    "        # compute ground-truth quality\n",
    "        q = metric([x, x_hat])\n",
    "        \n",
    "        qs = tf.keras.layers.Concatenate(name='concatenate_q')([q, q_hat])\n",
    "        \n",
    "        # prepare the output\n",
    "        # qs = tf.keras.layers.Subtract(name='subtract_q')([q, q_hat])\n",
    "\n",
    "        return super(Model_edsa, self).__init__(inputs=inputs_ed, outputs=qs, name=name)\n",
    "\n",
    "    def get_ed(self, ):\n",
    "        if self.extended_ed:\n",
    "            raise ValueError('to use this function \"extended_ed\" must be False.')\n",
    "        return self.get_layer(self.name_ed)\n",
    "    \n",
    "    def get_sa(self, ):\n",
    "        return self.get_layer(self.name_sa)\n",
    "    \n",
    "    def fit_sa_safe(self, x, y, **kwargs):\n",
    "        \n",
    "        self.get_ed().mode = 'test'\n",
    "        self.get_ed().trainable = False\n",
    "        \n",
    "        # self.get_sa().trainable = True\n",
    "        \n",
    "        super(Model_edsa, self).fit(x, y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e47af14-8103-428d-b182-8a89f390e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_augmentation(input_shape, zoom=0.1, rotation=0.05, flip=True, seed=5435, labels_augmentation=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    input_shape: the shape of the input image\n",
    "    zoom: zooming factor\n",
    "    rotation: rotation factor\n",
    "    flip: whether to flip\n",
    "    seed: seed for the random operations\n",
    "    labels_augmentation: whether to replicate the same augmentation to the labels or not \n",
    "                         (recommended True for autoencoders)\n",
    "    \"\"\"\n",
    "    \n",
    "    t_input = tf.keras.Input(input_shape)\n",
    "    \n",
    "    t = t_input\n",
    "    \n",
    "    if zoom:\n",
    "        t = tf.keras.layers.RandomZoom(zoom, zoom, seed=seed, fill_mode='constant')(t)\n",
    "    if flip:\n",
    "        t = tf.keras.layers.RandomFlip(seed=seed)(t)\n",
    "    if rotation:\n",
    "        t = tf.keras.layers.RandomRotation(rotation, seed=seed, fill_mode='constant')(t)\n",
    "    \n",
    "    seq_data_augmentation = tf.keras.Model(t_input, t, name='augmentation')\n",
    "\n",
    "    if labels_augmentation:\n",
    "        f_augmentation = lambda x, y: (seq_data_augmentation(x, training=True), \n",
    "                                       seq_data_augmentation(y, training=True))\n",
    "    else:\n",
    "        f_augmentation = lambda x, y: (seq_data_augmentation(x, training=True), y)\n",
    "    \n",
    "    return f_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7debca0-6a57-45d9-9dd1-67c026f62fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_ds(ds, batch_size, shuffle=True, buffer_size=1000, data_augmentation=False, augmentator=None):\n",
    "    \n",
    "    if data_augmentation==True and augmentator is None:\n",
    "        raise ValueError('if \"data:augmentation\" is True, provide a valid \"augmentator\"')\n",
    "    \n",
    "    ds =  (\n",
    "        ds\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size)\n",
    "    \n",
    "    if data_augmentation:\n",
    "        ds = ds.map(augmentator)\n",
    "        \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc805e35-a728-4b01-b54a-f16a83e06632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.image.psnr(y_true, y_pred, 1))\n",
    "\n",
    "class Psnr_edsa(tf.keras.losses.Loss):\n",
    "    \n",
    "    def tf_log10(x):\n",
    "        numerator = tf.math.log(x)\n",
    "        denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))  \n",
    "        return numerator / denominator\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mae = tf.math.abs(y_true - y_pred)\n",
    "        mae = 20*self.tf_log10(1/mae+1e-7)\n",
    "        return tf.reduce_mean(mae)\n",
    "\n",
    "class Mae_edsa(tf.keras.losses.MeanAbsoluteError):\n",
    "    \n",
    "    def call(self, _, y_pred):\n",
    "        return super(Mae_edsa, self).call(y_pred[..., 0], y_pred[..., 1])\n",
    "    \n",
    "class Mse_edsa(tf.keras.losses.MeanSquaredError):\n",
    "    \n",
    "    def call(self, _, y_pred):\n",
    "        return super(Mse_edsa, self).call(y_pred[0], y_pred[1])\n",
    "        \n",
    "    \n",
    "def mae(real, pred):\n",
    "    axis = (-1, -2)\n",
    "    if np.shape(real)[-1] in [1, 2]:\n",
    "        axis = axis + (-3, )\n",
    "\n",
    "    return np.mean(np.abs(real-pred), axis=axis)\n",
    "\n",
    "def mse(real, pred):\n",
    "    axis = (-1, -2)\n",
    "    if np.shape(real)[-1] in [2, 1]:\n",
    "        axis = axis + (-3, )\n",
    "    return np.mean((real-pred)**2, axis=axis)\n",
    "\n",
    "def var(real, pred):\n",
    "    axis = (-1, -2)\n",
    "    if np.shape(real)[-1] in [2, 1]:\n",
    "        axis = axis + (-3, )\n",
    "    return np.var(real-pred, axis=axis)\n",
    "\n",
    "def my_ssim(real, pred):\n",
    "\n",
    "    return [ssim(r, p, data_range=1, multichannel=True) for r, p in zip(real, pred)]\n",
    "\n",
    "def ifft(im):\n",
    "    im = im[... ,0] + 1j*im[..., 1]\n",
    "    im = np.fft.ifft2(im)\n",
    "    return np.concatenate((np.real(im)[..., np.newaxis], np.imag(im)[..., np.newaxis]), -1)\n",
    "\n",
    "def fft(im):\n",
    "    im = im[... ,0] + 1j*im[..., 1]\n",
    "    im = np.fft.fft2(im)\n",
    "    return np.concatenate((np.real(im)[..., np.newaxis], np.imag(im)[..., np.newaxis]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9041075f-9c97-414c-b603-55a33909bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_PSNR(metric, eps = 1e-7):\n",
    "    return 10 * np.log10(1/(metric+eps))\n",
    "def to_PSNR_mae(metric, eps = 1e-7):\n",
    "    return 2*to_PSNR(metric, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d171dd04-617e-45ea-992b-331b74c3c709",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff55956e-421e-442e-b123-40ffb1538e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_list = [4.0, 6.0, 8.0]\n",
    "dataset = 'IXI'\n",
    "sequence_type = 'unconstrained'\n",
    "\n",
    "loss = 'mae'\n",
    "\n",
    "folder = 'poppe'\n",
    "\n",
    "redundancy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08cf9a57-34d0-4084-a2e0-0ed1bb67fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager_incremental(folder, dataset, sequence_type, R_list, redundancy=redundancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59543ebb-ff1b-4d95-a061-82b870f6d0ef",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c104e33b-8bb6-44fa-8cdc-0629e1e271b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape xdata_ed = (12450, 256, 256, 1)\n",
      "shape vdata_ed = (825, 256, 256, 1)\n",
      "shape xdata_sa = (12450, 256, 256, 1)\n",
      "shape vdata_sa = (825, 256, 256, 1)\n",
      "shape tdata = (1200, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "xdata, vdata, tdata = uty.load_dataset(dataset=dataset)\n",
    "\n",
    "lx = len(xdata)\n",
    "lv = len(vdata)\n",
    "\n",
    "xdata_ed = xdata[lx//2:]\n",
    "vdata_ed = vdata[lv//2:]\n",
    "\n",
    "xdata_sa = xdata[:lx//2]\n",
    "vdata_sa = vdata[:lv//2]\n",
    "\n",
    "input_shape = np.shape(xdata_ed)[1:]\n",
    "\n",
    "print(f'shape xdata_ed = {np.shape(xdata_ed)}')\n",
    "print(f'shape vdata_ed = {np.shape(vdata_ed)}')\n",
    "print(f'shape xdata_sa = {np.shape(xdata_sa)}')\n",
    "print(f'shape vdata_sa = {np.shape(vdata_sa)}')\n",
    "print(f'shape tdata = {np.shape(tdata)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c5e966-67bd-46b1-8140-499bba0b9492",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9248a90-356d-4786-b7c5-08ca1dbbd8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=1000\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84acb679-acc0-4f11-a151-d9a7c6620c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_sa_training = True\n",
    "\n",
    "poly_degree_sa = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e3aa1b0-be71-485e-94b0-1cb02573ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_layers_additional_outputs = ['d_clip', 'undersample', 'add', 'masker']\n",
    "name_files_subresults_sa = ['x_hat', 'z', 'x_bar', 'mask']\n",
    "\n",
    "save_subresults_for_sa = False\n",
    "masker = None\n",
    "\n",
    "data_augmentation_ed = True\n",
    "data_augmentation_sa = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372eae3a-a2b0-4abf-bea5-590ad3b41288",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2876cd57-13f1-4490-8665-7e721792684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xds_ed = tf.data.Dataset.from_tensor_slices((xdata_ed, xdata_ed))\n",
    "vds_ed = tf.data.Dataset.from_tensor_slices((vdata_ed, vdata_ed))\n",
    "\n",
    "tds = tf.data.Dataset.from_tensor_slices((tdata, tdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a339b806-2fdc-4afd-913f-95a189a8571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xds_edsa = tf.data.Dataset.from_tensor_slices((xdata_sa, np.zeros((len(xdata_sa), 1))))\n",
    "vds_edsa = tf.data.Dataset.from_tensor_slices((vdata_sa, np.zeros((len(vdata_sa), 1))))\n",
    "\n",
    "tds_edsa = tf.data.Dataset.from_tensor_slices((tdata, np.zeros((len(tdata), 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "770e1552-9f3d-4191-9e3b-b08517429124",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_augmentation = get_f_augmentation(input_shape, labels_augmentation=True)\n",
    "f_augmentation_edsa = get_f_augmentation(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bbddae8-694d-4135-8d2f-0887014086ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xds_ed = refine_ds(xds_ed, batch_size, shuffle=True, \n",
    "                   data_augmentation=data_augmentation_ed,\n",
    "                   augmentator=f_augmentation)\n",
    "vds_ed = refine_ds(vds_ed, batch_size, shuffle=False)\n",
    "\n",
    "tds = refine_ds(tds, batch_size, shuffle=False)\n",
    "\n",
    "xds_edsa = refine_ds(xds_edsa, batch_size, shuffle=True, \n",
    "                     data_augmentation=data_augmentation_sa,\n",
    "                     augmentator=f_augmentation_edsa)\n",
    "vds_edsa = refine_ds(vds_edsa, batch_size, shuffle=False)\n",
    "tds_edsa = refine_ds(tds_edsa, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310e852-fa59-420b-9ca2-7034c76a4267",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bacc6cc-092e-46ef-ac51-42c2aa9bcbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t--- R=4.0 ---\n",
      "\n",
      "\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "loaded weights, skip training\n",
      "evaluation on tdata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 12:09:15.891155: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_DOUBLE\n",
      "      type: DT_DOUBLE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1200\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:2\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-09-01 12:09:19.706226: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 12s - loss: 0.0013 - psnr: 53.3813 - 12s/epoch - 1s/step\n",
      "model_ed_more creation\n",
      "model_ed_more prediction\n",
      "data_preparation\n",
      "line coef\n",
      "[-2.22466515e-05  4.90538417e-04  2.70991344e-04]\n",
      "loaded weights, skip training\n",
      "evaluation edsa on tdata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 12:10:52.801318: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_DOUBLE\n",
      "      type: DT_DOUBLE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1200\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:5\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 5s - loss: 3.2949e-04 - 5s/epoch - 454ms/step\n",
      "\t\t\t--- R=6.0 ---\n",
      "\n",
      "\n",
      "loaded weights, skip training\n",
      "evaluation on tdata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 12:10:59.107445: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_DOUBLE\n",
      "      type: DT_DOUBLE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1200\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:2\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 5s - loss: 0.0024 - psnr: 49.4994 - 5s/epoch - 496ms/step\n",
      "model_ed_more creation\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "model_ed_more prediction\n",
      "data_preparation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m x_bar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39mreal(x_bar), np\u001b[38;5;241m.\u001b[39mimag(x_bar)), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     86\u001b[0m x_bar \u001b[38;5;241m=\u001b[39m x_bar \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(np\u001b[38;5;241m.\u001b[39mrepeat(masker[np\u001b[38;5;241m.\u001b[39mnewaxis], \u001b[38;5;28mlen\u001b[39m(x_bar), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m mae_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m mae_true \u001b[38;5;241m=\u001b[39m mae(xdata_sa, x_hat) \n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline coef\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mmae\u001b[0;34m(real, pred)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(real)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m     30\u001b[0m     axis \u001b[38;5;241m=\u001b[39m axis \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, )\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mreal\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mpred\u001b[49m), axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for R in R_list:\n",
    "    \n",
    "    print(f'\\t\\t\\t--- R={R} ---\\n\\n')\n",
    "    \n",
    "    manager.R = R\n",
    "    \n",
    "    evaluation_best = np.infty\n",
    "    \n",
    "    path_weights = os.path.join(manager.path_ed_weights, 'weights')\n",
    "    \n",
    "    with tf_mirror_strategy.scope():\n",
    "        model_ed = Model_enc_dec(input_shape=input_shape, R=R, masker=masker, \n",
    "                                 sequence_type=sequence_type, \n",
    "                                 data_augmentation=False)\n",
    "        \n",
    "        model_ed.compile(tf.keras.optimizers.Adam(lr), loss, metrics=[psnr])\n",
    "        \n",
    "    if (os.path.isdir(manager.path_ed_weights) and\n",
    "        os.path.isfile(os.path.join(manager.path_ed_weights, 'checkpoint')) and \n",
    "        os.path.isfile(os.path.join(manager.path_ed_weights, 'weights.index')) ):\n",
    "        \n",
    "        model_ed.load_weights(path_weights)\n",
    "        print('loaded weights, skip training')\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        for index_redundancy in range(redundancy+1):\n",
    "\n",
    "            # model.re_initialize(seed=index_redundancy)\n",
    "            callbacks=manager.get_callbacks('enc_dec', index_redundancy=index_redundancy)\n",
    "\n",
    "            path_ckpt = manager.get_path_ed_checkpoint(index_redundancy)\n",
    "            if (os.path.isdir(path_ckpt) and\n",
    "                os.path.isfile(os.path.join(os.path.dirname(path_ckpt), 'checkpoint'))):\n",
    "                \n",
    "                model_ed.load_weights(path_ckpt)\n",
    "                \n",
    "                print('loaded weights from checkpoint')\n",
    "            \n",
    "            model_ed.fit_safe(x=xds_ed, y=None,\n",
    "                              batch_size=batch_size, epochs=epochs,\n",
    "                              verbose=2, callbacks=callbacks, validation_data=vds_ed)\n",
    "\n",
    "            evaluation = model_ed.evaluate_safe(vdata_sa, y=None, return_dict=True, batch_size=batch_size)['loss']\n",
    "            if evaluation<evaluation_best:\n",
    "                w = model_ed.get_weights()\n",
    "\n",
    "        model_ed.set_weights(w)\n",
    "        model_ed.save_weights(path_weights)\n",
    "    \n",
    "    masker = model_ed.mask\n",
    "    \n",
    "    print('evaluation on tdata')\n",
    "    model_ed.evaluate_safe(tds, None, batch_size=batch_size, verbose=2)\n",
    "    \n",
    "    ##### advanced sa training\n",
    "    \n",
    "    if advanced_sa_training:\n",
    "        \n",
    "        path_weights_edsa = os.path.join(manager.path_sa_weights, 'weights')\n",
    "        \n",
    "        print('model_ed_more creation') \n",
    "        # access intermediate outputs\n",
    "        model_ed_more = model_ed.propagate_layer_outputs(\n",
    "            names_layers_additional_outputs, \n",
    "            keep_old_outputs=True)\n",
    "        \n",
    "        print('model_ed_more prediction') \n",
    "        pred = model_ed_more.predict_safe(xdata_sa, batch_size=batch_size, verbose=False)\n",
    "        \n",
    "        # re-order outputs ed based on name list provided by user\n",
    "        name_outputs_ed = [o.name.split('/')[-2] for o in model_ed_more.outputs]\n",
    "        alias_outputs_ed = [name_files_subresults_sa[names_layers_additional_outputs.index(n)]\n",
    "                            for n in name_outputs_ed]\n",
    "        \n",
    "        x_hat = pred[alias_outputs_ed.index('x_hat')]\n",
    "        x_bar = pred[alias_outputs_ed.index('x_bar')]\n",
    "        z = pred[alias_outputs_ed.index('z')]\n",
    "        \n",
    "        print('data_preparation')\n",
    "        # get data for computing line coef (for self assessment)\n",
    "        x_bar = x_bar[..., 0] + 1j*x_bar[..., 1]\n",
    "        x_bar = np.fft.fft2(x_bar)[..., np.newaxis]\n",
    "        x_bar = np.concatenate((np.real(x_bar), np.imag(x_bar)), axis = -1)\n",
    "        \n",
    "        x_bar = x_bar * np.repeat(np.repeat(masker[np.newaxis], len(x_bar), 0), 2, -1)\n",
    "        mae_pred = mae(z, x_bar)\n",
    "        mae_true = mae(xdata_sa, x_hat) \n",
    "        \n",
    "        print('line coef')\n",
    "        line_coef = Model_self_assessment.get_line_coef(mae_pred, mae_true, \n",
    "                                                        poly_degree_sa, \n",
    "                                                        higher_degree_first=True)\n",
    "        \n",
    "        print(line_coef)\n",
    "        \n",
    "        with tf_mirror_strategy.scope():\n",
    "            model_sa = Model_self_assessment(input_shape=input_shape, \n",
    "                                             line_coef=line_coef)\n",
    "        \n",
    "        alias_inputs_sa = [i.name.replace('input_', '') for i in model_sa.inputs]\n",
    "        \n",
    "        with tf_mirror_strategy.scope():\n",
    "            model_edsa = Model_edsa(model_ed_more, model_sa, \n",
    "                                    loss, alias_outputs_ed, alias_inputs_sa)\n",
    "            if loss=='mae':\n",
    "                loss_edsa = Mae_edsa()\n",
    "            elif loss=='mse':\n",
    "                loss_edsa = Mse_edsa()\n",
    "            else:\n",
    "                raise ValueError('to be implemented')\n",
    "                \n",
    "            model_edsa.compile(tf.keras.optimizers.Adam(lr), loss_edsa)\n",
    "            \n",
    "        if (os.path.isdir(manager.path_sa_weights) and\n",
    "            os.path.isfile(os.path.join(manager.path_sa_weights, 'checkpoint')) and \n",
    "            os.path.isfile(os.path.join(manager.path_sa_weights, 'weights.index')) ):\n",
    "\n",
    "            model_edsa.load_weights(path_weights_edsa)\n",
    "            print('loaded weights, skip training')\n",
    "\n",
    "        else:\n",
    "            \n",
    "            evaluation_best = np.infty\n",
    "            \n",
    "            for index_redundancy in range(redundancy+1):\n",
    "\n",
    "                # model.re_initialize(seed=index_redundancy)\n",
    "                callbacks=manager.get_callbacks('self_assessment', index_redundancy=index_redundancy)\n",
    "\n",
    "                path_ckpt = manager.get_path_sa_checkpoint(index_redundancy)\n",
    "                if (os.path.isdir(path_ckpt) and\n",
    "                    os.path.isfile(os.path.join(os.path.dirname(path_ckpt), 'checkpoint'))):\n",
    "\n",
    "                    model_edsa.load_weights(path_ckpt)\n",
    "\n",
    "                    print('loaded weights from checkpoint')\n",
    "\n",
    "                model_edsa.fit_sa_safe(x=xds_edsa, y=None,\n",
    "                                       batch_size=batch_size, epochs=epochs,\n",
    "                                       verbose=2, callbacks=callbacks,\n",
    "                                       validation_data=vds_edsa)\n",
    "\n",
    "                evaluation = model_edsa.evaluate(vds_sa, None, return_dict=True)['loss']\n",
    "                if evaluation<evaluation_best:\n",
    "                    w = model_edsa.get_weights()\n",
    "\n",
    "            model_edsa.set_weights(w)\n",
    "            model_edsa.save_weights(path_weights_edsa)\n",
    "\n",
    "        print('evaluation edsa on tdata')\n",
    "        model_edsa.evaluate(tds_edsa, None, verbose=2)\n",
    "        \n",
    "    if save_subresults_for_sa:\n",
    "        model_ed_more = model_ed.propagate_layer_outputs(names_layers_additional_outputs, keep_old_outputs=False)\n",
    "        \n",
    "        output_names = [o.name.split('/')[-2] for o in model_ed_more.outputs if '/' in o.name]\n",
    "        \n",
    "        if name_files_subresults_sa is None:\n",
    "            name_files_subresults_sa = output_names\n",
    "        else:\n",
    "            # ordering the file names based on output order\n",
    "            name_files_subresults_sa = [\n",
    "                name_files_subresults_sa[names_layers_additional_outputs.index(n)] \n",
    "                for n in output_names]\n",
    "                \n",
    "        q, qm_fft, qm_ifft = {}, {}, {}\n",
    "        \n",
    "        for x, data_str in zip([xdata_sa, vdata_sa, tdata],\n",
    "                               ['xdata', 'vdata', 'tdata']):\n",
    "            \n",
    "            data_pred = model_ed_more.predict_safe(x)\n",
    "            \n",
    "            # exclude the outputs that are not included in the list of specified outputs\n",
    "            _or = lambda x, y: x | y\n",
    "            data_pred = [d for d, n in zip(data_pred, [o.name for o in model_ed_more.outputs]) \n",
    "                         if functools.reduce(_or, [a in n for a in names_layers_additional_outputs])]\n",
    "            \n",
    "            print('computing \"q\"')\n",
    "            # q = MAE(x_hat, x)\n",
    "            x_hat = data_pred[name_files_subresults_sa.index('x_hat')]\n",
    "            q['mae'] = mae(x, x_hat)\n",
    "            q['mse'] = mse(x, x_hat)\n",
    "            q['var'] = var(x, x_hat)\n",
    "            q['ssim'] = my_ssim(x, x_hat)\n",
    "            \n",
    "            print('computing \"q_measurement_fft\"')\n",
    "            # q_measurement_fft = MAE(F[x_bar], z)\n",
    "            x_bar = data_pred[name_files_subresults_sa.index('x_bar')]\n",
    "            z = data_pred[name_files_subresults_sa.index('z')]\n",
    "            fx_bar = fft(x_bar)\n",
    "            qm_fft['mae'] = mae(z, fx_bar)\n",
    "            qm_fft['mse'] = mse(z, fx_bar)\n",
    "            qm_fft['var'] = var(z, fx_bar)\n",
    "            qm_fft['ssim'] = my_ssim(z, fx_bar)\n",
    "            \n",
    "            print('computing \"q_measurement_ifft\"')\n",
    "            # q_measurement_fft = MAE(x_bar, iF(z))\n",
    "            zf = ifft(z)\n",
    "            qm_ifft['mae'] = mae(zf, x_bar)\n",
    "            qm_ifft['mse'] = mse(zf, x_bar)\n",
    "            qm_ifft['var'] = var(zf, x_bar)\n",
    "            qm_ifft['ssim'] = my_ssim(zf, x_bar)\n",
    "            \n",
    "            print('storing')\n",
    "            \n",
    "            data_pred += [q, qm_fft, qm_ifft]\n",
    "            name_files_subresults_sa += ['q', 'qm_fft', 'qm_ifft']\n",
    "            \n",
    "            # loop over multiple outputs of the same model\n",
    "            for n, d in zip(name_files_subresults_sa, data_pred):\n",
    "                \n",
    "                path_result = os.path.join(manager.main_path, f'{data_str}_sa_{n}.pkl')\n",
    "                \n",
    "                # if result is already stored, no need for restoring.\n",
    "                if not os.path.isfile(path_result):\n",
    "                    \n",
    "                    print('\\t', n)\n",
    "                    # store data\n",
    "                    with open(path_result, 'wb') as f:\n",
    "                        pkl.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f54df-ebef-4971-af71-232ac6bca33f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d0267ad-7f1c-45af-b38f-9e54f41838ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 10:22:30.702498: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_DOUBLE\n",
      "      type: DT_DOUBLE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1200\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:2\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/filippomartinini/miniconda3/envs/Tevildo/lib/python3.9/site-packages/keras/engine/training.py:2975: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use `experimental_local_results` instead.\n"
     ]
    }
   ],
   "source": [
    "# to get the reconstructed image x_hat:\n",
    "x_hat = model_ed.predict(tds)\n",
    "\n",
    "plt.imshow(x_hat[np.random.randint(0, len(tdata))], cmap='gray', vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc60e81-ab82-4405-9b5f-44b6ce8440cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c780fdc9-222c-42e4-958f-7f02afeee13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 08:38:58.813611: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_DOUBLE\n",
      "      type: DT_DOUBLE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1200\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:7\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 256\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/filippomartinini/miniconda3/envs/Tevildo/lib/python3.9/site-packages/keras/engine/training.py:2975: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use `experimental_local_results` instead.\n"
     ]
    }
   ],
   "source": [
    "# to get the real and predicted q:\n",
    "qs = model_edsa.predict(tds_edsa)\n",
    "q, q_hat = qs[..., 0], qs[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de351c7b-f856-4b5e-8c00-e3282e344b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01103323 -0.01024837  0.08918015]\n",
      "[array([[0.00455946],\n",
      "       [0.00060343]], dtype=float32), array([0.00651506], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "line_coef_2 = model_sa.get_layer_by_name('linear_reg_dense').get_weights()\n",
    "print(line_coef)\n",
    "print(line_coef_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e981d6a-3ad4-480e-88af-c54c052a6fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe13c3fddc0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(q)\n",
    "plt.plot(q_hat)\n",
    "# plt.title(np.mean(np.abs(to_PSNR_mae(q)-to_PSNR_mae(q_hat))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc6c5f3e-dc9c-440a-aa4a-4c05643d0858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_283924/3692216389.py:2: RuntimeWarning: invalid value encountered in log10\n",
      "  return 10 * np.log10(1/(metric+eps))\n"
     ]
    }
   ],
   "source": [
    "qP = np.nan_to_num(to_PSNR_mae(q), nan=100)\n",
    "q_hatP = np.nan_to_num(to_PSNR_mae(q_hat), nan=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1adedd5e-6130-4bf8-aa52-b6071fe7348a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(qP, label='true')\n",
    "plt.plot(q_hatP, label='pred')\n",
    "plt.title(np.mean(np.abs(qP-q_hatP)));\n",
    "plt.ylim(36, 45)\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
